{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR4erZYGZIE9"
   },
   "source": [
    "# Mini-Project 2: Classification of Textual Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvsGc-cLPGar"
   },
   "source": [
    "## 1. Acquiring, preprocessing, and analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1f4xampiPXaU"
   },
   "source": [
    "### 1.1. Loading and looking at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p4zdCkcO66gd"
   },
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XMPg7hmeXk8U",
    "outputId": "4944d1c2-1978-4728-8e63-17095286b46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOFKGfok6_a6"
   },
   "source": [
    "Importing the 20 newsgroups dataset and taking a look at the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARwzj50RZMdd"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "a7srfaaCZODT",
    "outputId": "4afe3589-7371-4fb6-a18e-b124148be415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset = 'train', remove = ('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Take a look at the data:\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qPrO0YjUYpcp",
    "outputId": "ed60f4b9-2342-40b8-a8cc-2efcfff585e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txNBSv97XHPe"
   },
   "source": [
    "Printing the first lines of the first loaded file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "T7_xVIW67sT0",
    "outputId": "97ab432c-5a3d-4589-f848-8bcfdf38e541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P9Mr1ztP8phM",
    "outputId": "d4a6cbbf-6c2a-4466-818b-bd826b98ec65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.target_names[newsgroups_train.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rkvjy01oqKkv"
   },
   "source": [
    "Taking a look at 10 first target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6pvbCW9b92HM",
    "outputId": "84200496-2922-4537-c5dc-64adb23338c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwcssZfXqR-i"
   },
   "source": [
    "Taking a look at the correspoding category names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "nz6B1IRgqWoC",
    "outputId": "91659679-c94f-47f1-e85b-197cf64a6e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n",
      "comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.graphics\n",
      "sci.space\n",
      "talk.politics.guns\n",
      "sci.med\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.mac.hardware\n"
     ]
    }
   ],
   "source": [
    "for t in newsgroups_train.target[:10]:\n",
    "    print(newsgroups_train.target_names[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyWSJh-Vftya"
   },
   "source": [
    "### 1.2. Stopwords romoval using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSrolqmjlvCw"
   },
   "source": [
    "It was decided to apply NLTK for removing stopwords and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Y6_ZPPE4fwWV",
    "outputId": "00f5aa05-cd7d-464e-a9e3-8fe069906d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Nick/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "bR0CqK6Ah2t6",
    "outputId": "65da9a90-65ed-420b-b4e2-c56a7329d881"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Nick/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLNVse2omSc3"
   },
   "source": [
    "The function for removing the punctuation from a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dutNCwVhmTH1"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(dataset):\n",
    "\n",
    "    filtered_dataset = []\n",
    "\n",
    "    for sentence in dataset:\n",
    "        word_tokens = word_tokenize(sentence) \n",
    "\n",
    "        filtered_words = [w for w in word_tokens if w.isalnum()] \n",
    "\n",
    "        filtered_sentence = \"\"\n",
    "\n",
    "        for word in filtered_words:\n",
    "            filtered_sentence += word + \" \"\n",
    "\n",
    "\n",
    "        filtered_dataset.append(filtered_sentence)\n",
    "\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrU3S6hBl33E"
   },
   "source": [
    "The function for removing the stopwords is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(dataset):\n",
    "\n",
    "    filtered_dataset = []\n",
    "\n",
    "    for sentence in dataset:\n",
    "        word_tokens = word_tokenize(sentence) \n",
    "\n",
    "        filtered_words = [w for w in word_tokens if not w in stopwords] \n",
    "\n",
    "        filtered_words = [] \n",
    "\n",
    "        for w in word_tokens: \n",
    "            if w not in stopwords: \n",
    "                filtered_words.append(w)\n",
    "\n",
    "        filtered_sentence = \"\"\n",
    "\n",
    "        for word in filtered_words:\n",
    "            filtered_sentence += word + \" \"\n",
    "\n",
    "\n",
    "        filtered_dataset.append(filtered_sentence)\n",
    "\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOyFxajUm54w"
   },
   "source": [
    "Now these functions can be applied to train data. First, the punctuatin is removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KH7zLkMXkzoU",
    "outputId": "8cef120b-6779-4e62-f2e0-b6b7f8613c62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 s, sys: 268 ms, total: 32 s\n",
      "Wall time: 34.6 s\n"
     ]
    }
   ],
   "source": [
    "%time filtered_train = remove_punctuation(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUvLjgSknBWs"
   },
   "source": [
    "Test whether everything is good for the first sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "QIPUB-JUk8Uc",
    "outputId": "aab6577c-b6ac-4d6f-9d6a-c5c02c1c0bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4piIRDg7k89u",
    "outputId": "4a19d1f5-10b3-48f0-bf08-40aa38ff657b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was wondering if anyone out there could enlighten me on this car I saw the other day It was a sports car looked to be from the late early 70s It was called a Bricklin The doors were really small In addition the front bumper was separate from the rest of the body This is all I know If anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucJPhjConIVy"
   },
   "source": [
    "Works as it should! Now the stopwords are filtered out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KL5P4lkWiCAf",
    "outputId": "d474430b-1e47-4689-cbe1-11da4d9dc66a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 139 ms, total: 21.6 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%time filtered_train = remove_stop_words(filtered_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYppMKk3nU1v"
   },
   "source": [
    "Testing once again, on a next sentence just in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "skwDW_JJghzd",
    "outputId": "d154c0c6-fc03-4db5-8cd6-35bf7ceb491f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "pgJk5ZfOnbOI",
    "outputId": "00d84568-b9be-4aec-a30b-7e6994e4cc34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I wondering anyone could enlighten car I saw day It sports car looked late early 70s It called Bricklin The doors really small In addition front bumper separate rest body This I know If anyone tellme model name engine specs years production car made history whatever info funky looking car please '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W_c1qGl6njT5",
    "outputId": "71aa2a9e-bb26-415b-f09d-af05579e2180"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AJ1KqPCmnmTc",
    "outputId": "ac564990-da62-4d7c-8a91-ffbde1276929"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlvLQQ1xacwJ"
   },
   "source": [
    "1.2. Extracting features from text files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODT62wThcs4M"
   },
   "source": [
    "Tokenizing text with scikit-learn :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rCoDnWoEcvhF",
    "outputId": "9cf15290-e0ce-45c6-abbe-9303d5dc6a34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 77086)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(filtered_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cHOsdhwidUmu",
    "outputId": "6bd19b30-8724-4395-a39f-be20811650b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9774"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEj95Ve1sNdn"
   },
   "source": [
    "Obtaining frequencies from occurancies. First we obtain term frequencies (TF)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T4Du4AJFsTzB",
    "outputId": "c482e138-1812-46a6-809d-28c48ba92457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 77086)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf = False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xp6XDPantxR5"
   },
   "source": [
    "... and then term frequencies times inverse document frequency (TF-IDF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AfjQLMTet7AK",
    "outputId": "c89e6b56-8908-4db7-dd76-5e7f97be7c7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 77086)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "izjlwFXpHj2x"
   },
   "source": [
    "### 1.3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "geHYvu_aHrz1",
    "outputId": "ecb52b45-ab36-4ee5-eafb-11e4713cb6d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 77086)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer_train = Normalizer().fit(X=X_train_tfidf)\n",
    "X_train_tfidf_normalized = normalizer_train.transform(X_train_tfidf)\n",
    "\n",
    "X_train_tfidf_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8VolDitPq8t"
   },
   "source": [
    "## 2. Training and testing the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NsGEKSinaxGn"
   },
   "source": [
    "Before we dive into training and testing, we need to define how do we do cross-validation. Cross-validation is essential for validation of many models and this case is not an exception. It was decided to consider $k=5$ folds, just like in Mini-Project 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATyhB07GbNxC"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def cross_validation(model, X, y, folds):\n",
    "    pipeline_tfidf = Pipeline([\n",
    "        ('tfidf',\n",
    "         TfidfVectorizer(sublinear_tf = True,\n",
    "                         smooth_idf = True,\n",
    "                         norm = \"l2\",\n",
    "                         lowercase = True,\n",
    "                         max_features = 50000,\n",
    "                         use_idf = True,\n",
    "                         encoding = \"utf-8\",\n",
    "                         decode_error = 'ignore',\n",
    "                         strip_accents = 'unicode',\n",
    "                         analyzer = \"word\")),\n",
    "          ('clf', model)],\n",
    "          verbose = True)\n",
    "\n",
    "    scores = cross_val_score(pipeline_tfidf,\n",
    "                             X,\n",
    "                             y,\n",
    "                             cv = folds,\n",
    "                             scoring = \"accuracy\")\n",
    "\n",
    "    print(\"Cross-validation scores:\", scores)\n",
    "    print(\"Cross-validation mean score:\", scores.mean())\n",
    "\n",
    "    return scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQkrRITOvSR3"
   },
   "source": [
    "Now we can actually start training the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ67lCcfP0Qb"
   },
   "source": [
    "### 2.1. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAyiDvUmvZIf"
   },
   "source": [
    "The logistic regression is used as the first classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlRyY0Apvw9O"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uS1rvGLjQYvx"
   },
   "source": [
    "#### 2.1.1. Training the logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvErPzQEv4_q"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_train_tfidf, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63H8-S7RyCeU"
   },
   "source": [
    "The model is tested on a couple of custom target values to check whether the trained model can correctly predict them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "BILl3v19yToV",
    "outputId": "b484ecde-f738-4549-8a11-951817363864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God love ' => soc.religion.christian\n",
      "'OpenGL GPU fast ' => rec.autos\n",
      "'Korea Russia Iran ' => talk.politics.mideast\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Korea, Russia, Iran']\n",
    "\n",
    "docs_new = remove_punctuation(docs_new)\n",
    "docs_new = remove_stop_words(docs_new)\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, newsgroups_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBMM6MiDbbjc"
   },
   "source": [
    "#### 2.1.2. Hyperparameter tuning for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hP9rStsvbsQV",
    "outputId": "852cde79-97af-42c3-dd2a-64e878d5412c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.9s\n",
      "Cross-validation scores: [0.71232877 0.71188688 0.72381794 0.72779496 0.72369584]\n",
      "Cross-validation mean score: 0.7199048781126279\n",
      "CPU times: user 1min 21s, sys: 47.3 s, total: 2min 8s\n",
      "Wall time: 1min 9s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  17.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  19.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  19.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.1s\n",
      "Cross-validation scores: [0.72558551 0.72691118 0.74060981 0.73133009 0.7382847 ]\n",
      "Cross-validation mean score: 0.73254425848023\n",
      "CPU times: user 1min 59s, sys: 1min 11s, total: 3min 10s\n",
      "Wall time: 1min 40s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  19.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  22.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.1s\n",
      "Cross-validation scores: [0.73133009 0.73353955 0.74856385 0.73663279 0.74270557]\n",
      "Cross-validation mean score: 0.7385543707971978\n",
      "CPU times: user 2min 16s, sys: 1min 21s, total: 3min 38s\n",
      "Wall time: 1min 54s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  25.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  24.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "Cross-validation scores: [0.73398144 0.73928414 0.75077331 0.74016792 0.74756852]\n",
      "Cross-validation mean score: 0.7423550657113063\n",
      "CPU times: user 2min 35s, sys: 1min 33s, total: 4min 8s\n",
      "Wall time: 2min 9s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  28.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  25.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.0s\n",
      "Cross-validation scores: [0.73663279 0.74149359 0.75475033 0.74281927 0.74933687]\n",
      "Cross-validation mean score: 0.7450065697631485\n",
      "CPU times: user 2min 43s, sys: 1min 39s, total: 4min 23s\n",
      "Wall time: 2min 16s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.3s\n",
      "Cross-validation scores: [0.73795846 0.74149359 0.75342466 0.74458683 0.7484527 ]\n",
      "Cross-validation mean score: 0.7451832481393486\n",
      "CPU times: user 2min 57s, sys: 1min 48s, total: 4min 45s\n",
      "Wall time: 2min 28s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  30.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  28.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.8s\n",
      "Cross-validation scores: [0.73707468 0.74193548 0.75254087 0.74502872 0.74668435]\n",
      "Cross-validation mean score: 0.7446528223022655\n",
      "CPU times: user 2min 59s, sys: 1min 48s, total: 4min 48s\n",
      "Wall time: 2min 29s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  30.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.4s\n",
      "Cross-validation scores: [0.73884224 0.74370305 0.7512152  0.74326116 0.74756852]\n",
      "Cross-validation mean score: 0.7449180352208069\n",
      "CPU times: user 3min 9s, sys: 1min 54s, total: 5min 4s\n",
      "Wall time: 2min 37s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  34.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  30.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.8s\n",
      "Cross-validation scores: [0.73928414 0.74414494 0.74988953 0.74326116 0.74668435]\n",
      "Cross-validation mean score: 0.7446528223022654\n",
      "CPU times: user 3min 20s, sys: 2min 1s, total: 5min 21s\n",
      "Wall time: 2min 46s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  38.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  35.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.5s\n",
      "Cross-validation scores: [0.73795846 0.74370305 0.74900574 0.74458683 0.74580018]\n",
      "Cross-validation mean score: 0.7442108528658272\n",
      "CPU times: user 3min 37s, sys: 2min 11s, total: 5min 49s\n",
      "Wall time: 3min\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  37.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  38.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.1s\n",
      "Cross-validation scores: [0.73795846 0.74326116 0.74900574 0.74591251 0.74447392]\n",
      "Cross-validation mean score: 0.7441223573943339\n",
      "CPU times: user 3min 45s, sys: 2min 18s, total: 6min 3s\n",
      "Wall time: 3min 7s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  34.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  37.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  35.2s\n",
      "Cross-validation scores: [0.73840035 0.74326116 0.74723818 0.74547061 0.744916  ]\n",
      "Cross-validation mean score: 0.7438572616883373\n",
      "CPU times: user 3min 36s, sys: 2min 12s, total: 5min 49s\n",
      "Wall time: 3min\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter C: 3.0\n",
      "Best accuracy: 0.7451832481393486\n"
     ]
    }
   ],
   "source": [
    "C_par = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]\n",
    "\n",
    "mu_max = 0\n",
    "C_max = C_par[0]\n",
    "\n",
    "for c in C_par:\n",
    "    %time scores, mu = cross_validation(model = LogisticRegression(C = c, max_iter = 500), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "    \n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        C_max = c\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter C:\", C_max)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hbji8ELa1F7I"
   },
   "source": [
    "Tuning the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ssyJwFuT1Ceo",
    "outputId": "d89a504e-a421-4ad4-ef43-14b4b6adbd81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "Cross-validation scores: [nan nan nan nan nan]\n",
      "Cross-validation mean score: nan\n",
      "CPU times: user 4.69 s, sys: 6.87 ms, total: 4.7 s\n",
      "Wall time: 4.72 s\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  28.3s\n",
      "Cross-validation scores: [0.73795846 0.74149359 0.75342466 0.74458683 0.7484527 ]\n",
      "Cross-validation mean score: 0.7451832481393486\n",
      "CPU times: user 2min 59s, sys: 1min 50s, total: 4min 49s\n",
      "Wall time: 2min 30s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "Cross-validation scores: [nan nan nan nan nan]\n",
      "Cross-validation mean score: nan\n",
      "CPU times: user 4.76 s, sys: 2.61 ms, total: 4.76 s\n",
      "Wall time: 4.78 s\n",
      "-----------------------------------------------------------------\n",
      "Best loss function: l2\n",
      "Best accuracy: 0.7451832481393486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "penalties = ['l1', 'l2', 'elasticnet']\n",
    "\n",
    "mu_max = 0\n",
    "penalty_best = penalties[0]\n",
    "\n",
    "for p in penalties:\n",
    "    %time scores, mu = cross_validation(model = LogisticRegression(C = 3, max_iter = 500, penalty = p), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "    \n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        penalty_best = p\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best loss function:\", penalty_best)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmVJJiYfQmkd"
   },
   "source": [
    "#### 2.1.3. Building a pipeline for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMgv1S2by7UW"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qidTQQhi1la8"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XTlkCdFkzOhb"
   },
   "source": [
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK8ALqxlzBb8"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(C = 3, max_iter = 500, penalty = 'l2')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "pFA4R6rR2SQm",
    "outputId": "0c0d5db5-8706-4c0d-f063-885d5c891b67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=3, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=500,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(filtered_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tj2a59R3zmHx"
   },
   "source": [
    "#### 2.1.4. Evaluation of the performance of logistic regression on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfecaAIzs5Pb"
   },
   "source": [
    "Loading the test dataset, filtering it, and predicting its target values with logistic regression with the tuned parameter $C = 3$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZuTMydNqxjQp"
   },
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset = 'test', remove = ('headers', 'footers', 'quotes'))\n",
    "docs_test = newsgroups_test.data\n",
    "\n",
    "# Filtering:\n",
    "filtered_test = remove_punctuation(docs_test)\n",
    "filtered_test = remove_stop_words(filtered_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xqY8_JNwZRlc",
    "outputId": "8a349b1e-ab58-46c7-81b2-843f80b40008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6802973977695167\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(filtered_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2-xtmsvhZPN"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "fGKRtMmRhbSs",
    "outputId": "cd798749-50b0-4d7d-e2ac-2cafae843801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.49      0.46      0.48       319\n",
      "           comp.graphics       0.62      0.68      0.65       389\n",
      " comp.os.ms-windows.misc       0.64      0.60      0.62       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.64      0.63       392\n",
      "   comp.sys.mac.hardware       0.74      0.68      0.71       385\n",
      "          comp.windows.x       0.78      0.66      0.72       395\n",
      "            misc.forsale       0.76      0.79      0.77       390\n",
      "               rec.autos       0.74      0.71      0.72       396\n",
      "         rec.motorcycles       0.50      0.81      0.62       398\n",
      "      rec.sport.baseball       0.82      0.79      0.80       397\n",
      "        rec.sport.hockey       0.90      0.86      0.88       399\n",
      "               sci.crypt       0.83      0.68      0.75       396\n",
      "         sci.electronics       0.57      0.61      0.59       393\n",
      "                 sci.med       0.78      0.75      0.76       396\n",
      "               sci.space       0.71      0.74      0.73       394\n",
      "  soc.religion.christian       0.67      0.77      0.72       398\n",
      "      talk.politics.guns       0.58      0.68      0.63       364\n",
      "   talk.politics.mideast       0.84      0.72      0.77       376\n",
      "      talk.politics.misc       0.58      0.46      0.51       310\n",
      "      talk.religion.misc       0.43      0.28      0.34       251\n",
      "\n",
      "                accuracy                           0.68      7532\n",
      "               macro avg       0.68      0.67      0.67      7532\n",
      "            weighted avg       0.69      0.68      0.68      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "                                    target_names = newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIek9YLfRTVV"
   },
   "source": [
    "### 2.2. Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-s9QW27gzJSU"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7maNSudbRnUi"
   },
   "source": [
    "#### 2.2.1. Training the decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tr6s7QwKRmiv"
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier().fit(X_train_tfidf, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zqv0uCoVRz3e"
   },
   "source": [
    "The model is tested on a couple of custom target values to check whether the trained model can correctly predict them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5_uOb_f7RyM-",
    "outputId": "2952a218-09ff-4981-98ee-7f619a3b9c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God love ' => soc.religion.christian\n",
      "'OpenGL GPU fast ' => rec.autos\n",
      "'Korea Russia Iran ' => rec.autos\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Korea, Russia, Iran']\n",
    "\n",
    "# Filtering:\n",
    "\n",
    "docs_new = remove_punctuation(docs_new)\n",
    "docs_new = remove_stop_words(docs_new)\n",
    "\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, newsgroups_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCcSmF-V4OYF"
   },
   "source": [
    "#### 2.2.2. Hyperparameter tuning for decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gq9TBTO07hYl"
   },
   "source": [
    "First we tune `min_samples_split`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kEd1dLIC4W7k",
    "outputId": "694e4614-9939-4209-a785-a9369f87433d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   8.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   8.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   8.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   8.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   7.9s\n",
      "Cross-validation scores: [0.47105612 0.45558992 0.48342908 0.48298719 0.47126437]\n",
      "Cross-validation mean score: 0.4728653348977301\n",
      "CPU times: user 46.6 s, sys: 0 ns, total: 46.6 s\n",
      "Wall time: 46.7 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   7.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   7.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   7.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   7.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.9s\n",
      "Cross-validation scores: [0.47459125 0.4719399  0.48431286 0.49049934 0.48054819]\n",
      "Cross-validation mean score: 0.4803783073961506\n",
      "CPU times: user 41.8 s, sys: 5.13 ms, total: 41.8 s\n",
      "Wall time: 41.9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   7.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.6s\n",
      "Cross-validation scores: [0.47017234 0.46266019 0.48342908 0.48254529 0.47480106]\n",
      "Cross-validation mean score: 0.47472159090243116\n",
      "CPU times: user 40 s, sys: 11.8 ms, total: 40 s\n",
      "Wall time: 40.1 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.1s\n",
      "Cross-validation scores: [0.46133451 0.45735749 0.46796288 0.48166151 0.46772767]\n",
      "Cross-validation mean score: 0.4672088137582523\n",
      "CPU times: user 37.9 s, sys: 9.31 ms, total: 37.9 s\n",
      "Wall time: 38 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.2s\n",
      "Cross-validation scores: [0.45956695 0.4516129  0.46884666 0.46575342 0.4571176 ]\n",
      "Cross-validation mean score: 0.46057950663676966\n",
      "CPU times: user 37 s, sys: 6.59 ms, total: 37 s\n",
      "Wall time: 37.1 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.1s\n",
      "Cross-validation scores: [0.45824127 0.45293858 0.46486964 0.46398586 0.4571176 ]\n",
      "Cross-validation mean score: 0.45943058927044184\n",
      "CPU times: user 36.8 s, sys: 8.71 ms, total: 36.8 s\n",
      "Wall time: 36.8 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.3s\n",
      "Cross-validation scores: [0.45514803 0.44365886 0.46619532 0.46928856 0.45932803]\n",
      "Cross-validation mean score: 0.4587237585530971\n",
      "CPU times: user 37.3 s, sys: 19.7 ms, total: 37.3 s\n",
      "Wall time: 37.4 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.0s\n",
      "Cross-validation scores: [0.45603182 0.44410075 0.46486964 0.46575342 0.45844385]\n",
      "Cross-validation mean score: 0.4578398978219174\n",
      "CPU times: user 37.4 s, sys: 8.34 ms, total: 37.4 s\n",
      "Wall time: 37.5 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.1s\n",
      "Cross-validation scores: [0.45779938 0.44763588 0.46884666 0.46486964 0.45932803]\n",
      "Cross-validation mean score: 0.4596959194015284\n",
      "CPU times: user 37 s, sys: 15 ms, total: 37 s\n",
      "Wall time: 37.1 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   5.9s\n",
      "Cross-validation scores: [0.45382236 0.44277508 0.4670791  0.46531153 0.45667551]\n",
      "Cross-validation mean score: 0.4571327154669376\n",
      "CPU times: user 36 s, sys: 8.3 ms, total: 36.1 s\n",
      "Wall time: 36.1 s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter min_samples_splits: 0.020000000000000004\n",
      "Best accuracy: 0.4803783073961506\n"
     ]
    }
   ],
   "source": [
    "min_samples_splits = np.linspace(0.01, 0.1, 10, endpoint = True)\n",
    "\n",
    "mu_max = 0\n",
    "min_samples_split_max = min_samples_splits[0]\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "    %time scores, mu = cross_validation(model = DecisionTreeClassifier(min_samples_split = min_samples_split), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "    \n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        min_samples_split_max = min_samples_split\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter min_samples_splits:\", min_samples_split_max)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ywtUn378GDX"
   },
   "source": [
    "Tuning `min_samples_leaf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fmRYR9dW8IkF",
    "outputId": "87b69be1-a4b1-4cf8-8d95-611667894c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   4.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   4.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   4.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   4.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   4.2s\n",
      "Cross-validation scores: [0.43747238 0.43835616 0.44984534 0.44851966 0.45181256]\n",
      "Cross-validation mean score: 0.44520122072958557\n",
      "CPU times: user 26.8 s, sys: 23.7 ms, total: 26.8 s\n",
      "Wall time: 26.9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.3s\n",
      "Cross-validation scores: [0.42068051 0.42200619 0.43216969 0.42907645 0.43810787]\n",
      "Cross-validation mean score: 0.42840814033311025\n",
      "CPU times: user 22.8 s, sys: 23.9 ms, total: 22.8 s\n",
      "Wall time: 22.9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "Cross-validation scores: [0.38709677 0.3857711  0.4060981  0.40344675 0.40362511]\n",
      "Cross-validation mean score: 0.3972075673981902\n",
      "CPU times: user 20.2 s, sys: 25 ms, total: 20.2 s\n",
      "Wall time: 20.2 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "Cross-validation scores: [0.36632788 0.37693327 0.39328325 0.38930623 0.3872679 ]\n",
      "Cross-validation mean score: 0.3826237090503322\n",
      "CPU times: user 18.1 s, sys: 34.9 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "Cross-validation scores: [0.34600088 0.3756076  0.38444543 0.36500221 0.37533156]\n",
      "Cross-validation mean score: 0.3692775370362339\n",
      "CPU times: user 17.1 s, sys: 33.2 ms, total: 17.1 s\n",
      "Wall time: 17.2 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "Cross-validation scores: [0.35351304 0.36897923 0.36853734 0.35616438 0.37135279]\n",
      "Cross-validation mean score: 0.3637093550848561\n",
      "CPU times: user 16.3 s, sys: 33 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "Cross-validation scores: [0.32390632 0.34953601 0.36279275 0.34644278 0.35632184]\n",
      "Cross-validation mean score: 0.34779994006531856\n",
      "CPU times: user 15.2 s, sys: 34.7 ms, total: 15.2 s\n",
      "Wall time: 15.3 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "Cross-validation scores: [0.30844012 0.34202386 0.34202386 0.32699956 0.34394341]\n",
      "Cross-validation mean score: 0.33268616380140603\n",
      "CPU times: user 14.4 s, sys: 38.5 ms, total: 14.5 s\n",
      "Wall time: 14.5 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "Cross-validation scores: [0.29827662 0.3247901  0.33097658 0.32258065 0.33289125]\n",
      "Cross-validation mean score: 0.321903039438505\n",
      "CPU times: user 13.7 s, sys: 34.4 ms, total: 13.8 s\n",
      "Wall time: 13.8 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "Cross-validation scores: [0.29562528 0.31948741 0.32258065 0.32876712 0.33244916]\n",
      "Cross-validation mean score: 0.3197819221528975\n",
      "CPU times: user 13.6 s, sys: 43.7 ms, total: 13.7 s\n",
      "Wall time: 13.7 s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter min_samples_leaf: 0.001\n",
      "Best accuracy: 0.44520122072958557\n"
     ]
    }
   ],
   "source": [
    "min_samples_leafs = np.linspace(0.001, 0.01, 10, endpoint=True)\n",
    "\n",
    "mu_max = 0\n",
    "min_samples_leaf_max = min_samples_leafs[0]\n",
    "\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    %time scores, mu = cross_validation(model = DecisionTreeClassifier(min_samples_leaf = min_samples_leaf, min_samples_split = 0.02), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        min_samples_leaf_max = min_samples_leaf\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter min_samples_leaf:\", min_samples_leaf_max)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqyDbq0qTNzi"
   },
   "source": [
    "#### 2.2.3. Building a pipeline for decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4QLX13kTawt"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJ8IjlTLR5fd"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', DecisionTreeClassifier(min_samples_leaf = 0.001, min_samples_split = 0.02)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxiIP7jlTZl3"
   },
   "source": [
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "k7BmcV8nTTm6",
    "outputId": "fb68fed2-e460-4e8e-d688-0e856b75c70a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=0.001,\n",
       "                                        min_samples_split=0.02,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(filtered_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmHxEwCyTi8Q"
   },
   "source": [
    "#### 2.2.4. Evaluation of the performance of decision tree on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgQvVIG5TnMC"
   },
   "source": [
    "Loading the test dataset and predicting its target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZIQYlJ79TgiW",
    "outputId": "9a708c4b-32b9-489c-9ad5-2f53621c9301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.4114445034519384\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(filtered_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "YkQipowkGbF6",
    "outputId": "acbbf767-dbbd-4490-80f9-a9e397ad5baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.17      0.24      0.20       319\n",
      "           comp.graphics       0.35      0.45      0.39       389\n",
      " comp.os.ms-windows.misc       0.53      0.41      0.46       394\n",
      "comp.sys.ibm.pc.hardware       0.42      0.41      0.41       392\n",
      "   comp.sys.mac.hardware       0.60      0.37      0.46       385\n",
      "          comp.windows.x       0.48      0.39      0.43       395\n",
      "            misc.forsale       0.64      0.55      0.59       390\n",
      "               rec.autos       0.45      0.42      0.44       396\n",
      "         rec.motorcycles       0.64      0.45      0.53       398\n",
      "      rec.sport.baseball       0.19      0.42      0.26       397\n",
      "        rec.sport.hockey       0.56      0.62      0.59       399\n",
      "               sci.crypt       0.68      0.40      0.50       396\n",
      "         sci.electronics       0.23      0.42      0.30       393\n",
      "                 sci.med       0.40      0.35      0.37       396\n",
      "               sci.space       0.59      0.45      0.51       394\n",
      "  soc.religion.christian       0.50      0.58      0.54       398\n",
      "      talk.politics.guns       0.31      0.44      0.36       364\n",
      "   talk.politics.mideast       0.71      0.40      0.51       376\n",
      "      talk.politics.misc       0.32      0.17      0.23       310\n",
      "      talk.religion.misc       0.25      0.07      0.11       251\n",
      "\n",
      "                accuracy                           0.41      7532\n",
      "               macro avg       0.45      0.40      0.41      7532\n",
      "            weighted avg       0.46      0.41      0.42      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "                                    target_names = newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmB2r1czUK-h"
   },
   "source": [
    "### 2.3. Support vector machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2luHbKpTqYo"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLNCcZn5UXpu"
   },
   "source": [
    "#### 2.3.1. Training the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKyOMVfrUVL9"
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC().fit(X_train_tfidf, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2yAFU_SUiuj"
   },
   "source": [
    "The model is tested on a couple of custom target values to check whether the trained model can correctly predict them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "knzjzAfoUgls",
    "outputId": "77b4deb6-b5a4-4ebb-e0d5-0dc685dddc27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God love ' => soc.religion.christian\n",
      "'OpenGL GPU fast ' => rec.autos\n",
      "'Korea Russia Iran ' => talk.politics.misc\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Korea, Russia, Iran']\n",
    "\n",
    "# Filtering:\n",
    "docs_new = remove_punctuation(docs_new)\n",
    "docs_new = remove_stop_words(docs_new)\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, newsgroups_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dJpub9QGiXq"
   },
   "source": [
    "#### 2.3.2. Hyperparameter tuning for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7TA-m7gGq2K"
   },
   "source": [
    "Tuning the penalty parameter $C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fik6lj31Gsvy",
    "outputId": "1bf9417a-70a1-437f-847c-06e8e205d278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "Cross-validation scores: [0.7410517  0.75740168 0.75695979 0.75475033 0.75906278]\n",
      "Cross-validation mean score: 0.7538452552166419\n",
      "CPU times: user 9.7 s, sys: 49 ms, total: 9.75 s\n",
      "Wall time: 9.79 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "Cross-validation scores: [0.74458683 0.76182059 0.75784357 0.75342466 0.75994695]\n",
      "Cross-validation mean score: 0.7555245202783564\n",
      "CPU times: user 10.2 s, sys: 47.2 ms, total: 10.3 s\n",
      "Wall time: 10.3 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "Cross-validation scores: [0.7410517  0.75607601 0.75872735 0.74856385 0.75729443]\n",
      "Cross-validation mean score: 0.7523426685311275\n",
      "CPU times: user 10.8 s, sys: 45.6 ms, total: 10.9 s\n",
      "Wall time: 10.9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "Cross-validation scores: [0.73840035 0.75519222 0.75828546 0.74591251 0.75862069]\n",
      "Cross-validation mean score: 0.7512822466362931\n",
      "CPU times: user 11.3 s, sys: 42.4 ms, total: 11.4 s\n",
      "Wall time: 11.4 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "Cross-validation scores: [0.74016792 0.75386655 0.75607601 0.74458683 0.75685234]\n",
      "Cross-validation mean score: 0.7503099295044684\n",
      "CPU times: user 11.8 s, sys: 50.2 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "Cross-validation scores: [0.74060981 0.75033142 0.75386655 0.74281927 0.75419982]\n",
      "Cross-validation mean score: 0.7483653733825157\n",
      "CPU times: user 12.3 s, sys: 41 ms, total: 12.3 s\n",
      "Wall time: 12.3 s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter C: 0.5\n",
      "Best accuracy: 0.7555245202783564\n"
     ]
    }
   ],
   "source": [
    "C_par = [0.25, 0.5, 0.75, 1, 1.25, 1.5]\n",
    "\n",
    "mu_max = 0\n",
    "C_max = C_par[0]\n",
    "\n",
    "for c in C_par:\n",
    "    %time scores, mu = cross_validation(model = LinearSVC(C = c), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        C_max = c\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter C:\", C_max)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2VI42GW4rT2"
   },
   "source": [
    "Tuning the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "QRzsasv54qt_",
    "outputId": "0472798d-909d-4d2f-d123-901cd3db470b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "Cross-validation scores: [nan nan nan nan nan]\n",
      "Cross-validation mean score: nan\n",
      "CPU times: user 4.99 s, sys: 38.1 ms, total: 5.03 s\n",
      "Wall time: 5.05 s\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "Cross-validation scores: [0.74458683 0.76182059 0.75784357 0.75342466 0.75994695]\n",
      "Cross-validation mean score: 0.7555245202783564\n",
      "CPU times: user 10.4 s, sys: 37.8 ms, total: 10.4 s\n",
      "Wall time: 10.5 s\n",
      "-----------------------------------------------------------------\n",
      "Best loss function: l2\n",
      "Best accuracy: 0.7555245202783564\n"
     ]
    }
   ],
   "source": [
    "penalties = ['l1', 'l2']\n",
    "\n",
    "mu_max = 0\n",
    "penalty_best = penalties[0]\n",
    "\n",
    "for p in penalties:\n",
    "    %time scores, mu = cross_validation(model = LinearSVC(C = 0.5, penalty = p), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        penalty_best = p\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best loss function:\", penalty_best)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrBZvdowUoMr"
   },
   "source": [
    "#### 2.3.3. Building a pipeline for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nWPIs0JUvJo"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rm3n_G_YUmfA"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC(C = 0.5, penalty = 'l2')),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgRZNZdnVIUk"
   },
   "source": [
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "D_m3YdO3U3U_",
    "outputId": "9cea9c6e-3c36-4834-ed56-52837829ccc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=0.5, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(filtered_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLiYs4_cVOJ6"
   },
   "source": [
    "#### 2.3.4. Evaluation of the performance of SVM on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-E2qMqO8VUhl"
   },
   "source": [
    "Loading the test dataset and predicting its target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rqvr2ZVmU5M6",
    "outputId": "3581a333-5d98-4d3a-d17e-2d5908dc3806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6891927774827403\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(filtered_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "l_5_CVZBvscu",
    "outputId": "2932999f-f5c1-419c-c212-dd8d9d624f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.53      0.46      0.49       319\n",
      "           comp.graphics       0.64      0.68      0.66       389\n",
      " comp.os.ms-windows.misc       0.63      0.63      0.63       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.65      0.65       392\n",
      "   comp.sys.mac.hardware       0.74      0.71      0.72       385\n",
      "          comp.windows.x       0.77      0.68      0.72       395\n",
      "            misc.forsale       0.73      0.79      0.76       390\n",
      "               rec.autos       0.79      0.70      0.75       396\n",
      "         rec.motorcycles       0.78      0.77      0.78       398\n",
      "      rec.sport.baseball       0.55      0.84      0.66       397\n",
      "        rec.sport.hockey       0.89      0.87      0.88       399\n",
      "               sci.crypt       0.81      0.71      0.76       396\n",
      "         sci.electronics       0.61      0.58      0.59       393\n",
      "                 sci.med       0.79      0.77      0.78       396\n",
      "               sci.space       0.73      0.74      0.74       394\n",
      "  soc.religion.christian       0.63      0.78      0.70       398\n",
      "      talk.politics.guns       0.59      0.68      0.63       364\n",
      "   talk.politics.mideast       0.82      0.73      0.78       376\n",
      "      talk.politics.misc       0.58      0.47      0.52       310\n",
      "      talk.religion.misc       0.42      0.29      0.34       251\n",
      "\n",
      "                accuracy                           0.69      7532\n",
      "               macro avg       0.69      0.68      0.68      7532\n",
      "            weighted avg       0.69      0.69      0.69      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "                                    target_names = newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3CoSYiPzy4K"
   },
   "source": [
    "### 2.4. Ada boost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MkaHOf5Cz4lb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtS1XPUWz8id"
   },
   "source": [
    "#### 2.4.1. Training the Ada boost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7X5h7gCC0D5P"
   },
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier().fit(X_train_tfidf, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TivQgsXJLKPC"
   },
   "source": [
    "The model is tested on a couple of custom target values to check whether the trained model can correctly predict them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "M48sGMzALS0O",
    "outputId": "75f2e75e-9e05-49a6-d454-545ccdcb41c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God love ' => soc.religion.christian\n",
      "'OpenGL GPU fast ' => sci.electronics\n",
      "'Korea Russia Iran ' => sci.electronics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Korea, Russia, Iran']\n",
    "\n",
    "# Filtering:\n",
    "docs_new = remove_punctuation(docs_new)\n",
    "docs_new = remove_stop_words(docs_new)\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, newsgroups_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hIg1Upmv9tl"
   },
   "source": [
    "#### 2.4.2. Hyperparameter tuning for Ada boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvTACBMPwTBB"
   },
   "source": [
    "First we tune the maximum number of estmators: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1V6pw5u6wTmB",
    "outputId": "78330edd-e935-40a4-c129-12aa75fc04d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   6.7s\n",
      "Cross-validation scores: [0.3804684  0.38709677 0.39726027 0.39946973 0.39434129]\n",
      "Cross-validation mean score: 0.39172729485558044\n",
      "CPU times: user 39.8 s, sys: 388 ms, total: 40.2 s\n",
      "Wall time: 40.2 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.6s\n",
      "Cross-validation scores: [0.43923995 0.43923995 0.44498453 0.43968184 0.44916004]\n",
      "Cross-validation mean score: 0.4424612602770983\n",
      "CPU times: user 1min 13s, sys: 750 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.1s\n",
      "Cross-validation scores: [0.45868316 0.46840477 0.45647371 0.4617764  0.4602122 ]\n",
      "Cross-validation mean score: 0.4611100496863979\n",
      "CPU times: user 1min 47s, sys: 1.06 s, total: 1min 48s\n",
      "Wall time: 1min 48s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.2s\n",
      "Cross-validation scores: [0.46531153 0.45117101 0.44940345 0.46398586 0.45800177]\n",
      "Cross-validation mean score: 0.45757472397422416\n",
      "CPU times: user 2min 22s, sys: 1.44 s, total: 2min 23s\n",
      "Wall time: 2min 23s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter n_estimators: 150\n",
      "Best accuracy: 0.4611100496863979\n"
     ]
    }
   ],
   "source": [
    "ns = [50, 100, 150, 200]\n",
    "\n",
    "mu_max = 0\n",
    "n_best = ns[0]\n",
    "\n",
    "for n in ns:\n",
    "    %time scores, mu = cross_validation(model = AdaBoostClassifier(n_estimators = n), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        n_best = n\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter n_estimators:\", n_best)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RoIUQbElzR5u"
   },
   "source": [
    "Tuning the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p5n-0BtBzaMf",
    "outputId": "483079ab-4256-4e9e-cd8b-e513a285aa69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "Cross-validation scores: [0.27662395 0.29518338 0.27618206 0.28192665 0.28116711]\n",
      "Cross-validation mean score: 0.2822166298814629\n",
      "CPU times: user 1min 49s, sys: 1.07 s, total: 1min 51s\n",
      "Wall time: 1min 51s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.8s\n",
      "Cross-validation scores: [0.41184269 0.41449403 0.42996023 0.41493593 0.4204244 ]\n",
      "Cross-validation mean score: 0.41833145597907057\n",
      "CPU times: user 1min 50s, sys: 1.12 s, total: 1min 51s\n",
      "Wall time: 1min 51s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "Cross-validation scores: [0.46575342 0.4617764  0.47149801 0.46045073 0.47391689]\n",
      "Cross-validation mean score: 0.46667909119643924\n",
      "CPU times: user 1min 49s, sys: 1.13 s, total: 1min 50s\n",
      "Wall time: 1min 51s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "Cross-validation scores: [0.45824127 0.46840477 0.45647371 0.4617764  0.4602122 ]\n",
      "Cross-validation mean score: 0.4610216714274496\n",
      "CPU times: user 1min 49s, sys: 1.1 s, total: 1min 50s\n",
      "Wall time: 1min 50s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "Cross-validation scores: [0.45028723 0.45293858 0.46266019 0.45779938 0.45755968]\n",
      "Cross-validation mean score: 0.4562490110191514\n",
      "CPU times: user 1min 49s, sys: 1.08 s, total: 1min 50s\n",
      "Wall time: 1min 50s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.9s\n",
      "Cross-validation scores: [0.06495802 0.08307556 0.07512152 0.06716748 0.06542882]\n",
      "Cross-validation mean score: 0.07115028093893501\n",
      "CPU times: user 1min 12s, sys: 1.13 s, total: 1min 13s\n",
      "Wall time: 1min 13s\n",
      "-----------------------------------------------------------------\n",
      "Best learning rate: 0.5\n",
      "Best accuracy: 0.46667909119643924\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.01, 0.1, 0.5, 1, 1.5, 10]\n",
    "\n",
    "mu_max = 0\n",
    "lr_best = ns[0]\n",
    "\n",
    "for lr in lrs:\n",
    "    %time scores, mu = cross_validation(model = AdaBoostClassifier(n_estimators = 150, learning_rate = lr), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        lr_best = lr\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best learning rate:\", lr_best)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3iIPB6nLsxI"
   },
   "source": [
    "#### 2.4.3. Building a pipeline for Ada boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IPjbdPjVMmKm"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhxPMjYPMqOY"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', AdaBoostClassifier(n_estimators = 150, learning_rate = 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsW0obbVM8FZ"
   },
   "source": [
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "GCNp8g_-M9hD",
    "outputId": "e391079a-2fd1-4f78-cac0-e77d16ff619a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                    learning_rate=0.5, n_estimators=150,\n",
       "                                    random_state=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(filtered_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aiIrtreNFJ5"
   },
   "source": [
    "#### 2.4.4. Evaluation of the performance of Ada boost on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHRaRXNyNjTe"
   },
   "source": [
    "Loading the test dataset and predicting its target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ElJL8ltGNkxf",
    "outputId": "f5fabbcc-f68e-4f09-dbfa-7568b4fa1502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.4486192246415295\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(filtered_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "LyZV3mGD6i_c",
    "outputId": "20b7cc67-4a2e-44a5-946c-a87cfb5477cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.39      0.29      0.33       319\n",
      "           comp.graphics       0.52      0.41      0.46       389\n",
      " comp.os.ms-windows.misc       0.62      0.46      0.53       394\n",
      "comp.sys.ibm.pc.hardware       0.45      0.46      0.46       392\n",
      "   comp.sys.mac.hardware       0.78      0.41      0.54       385\n",
      "          comp.windows.x       0.73      0.46      0.57       395\n",
      "            misc.forsale       0.72      0.54      0.62       390\n",
      "               rec.autos       0.58      0.43      0.50       396\n",
      "         rec.motorcycles       0.91      0.46      0.61       398\n",
      "      rec.sport.baseball       0.62      0.51      0.56       397\n",
      "        rec.sport.hockey       0.88      0.51      0.65       399\n",
      "               sci.crypt       0.81      0.45      0.58       396\n",
      "         sci.electronics       0.11      0.71      0.19       393\n",
      "                 sci.med       0.83      0.35      0.49       396\n",
      "               sci.space       0.74      0.46      0.57       394\n",
      "  soc.religion.christian       0.61      0.48      0.54       398\n",
      "      talk.politics.guns       0.55      0.38      0.45       364\n",
      "   talk.politics.mideast       0.92      0.55      0.68       376\n",
      "      talk.politics.misc       0.25      0.33      0.29       310\n",
      "      talk.religion.misc       0.29      0.15      0.19       251\n",
      "\n",
      "                accuracy                           0.45      7532\n",
      "               macro avg       0.61      0.44      0.49      7532\n",
      "            weighted avg       0.63      0.45      0.50      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "                                    target_names = newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0UAfTdSVe0b"
   },
   "source": [
    "### 2.5. Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkXEOfOFVXyN"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35sesmAwVodE"
   },
   "source": [
    "#### 2.5.1. Training the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czEoqoCKVntn"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier().fit(X_train_tfidf, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-S1q815V0sZ"
   },
   "source": [
    "The model is tested on a couple of custom target values to check whether the trained model can correctly predict them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ev7zjaeaVtKb",
    "outputId": "e59ffe8c-5b10-4d13-d618-028ab6207e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God love ' => soc.religion.christian\n",
      "'OpenGL GPU fast ' => rec.autos\n",
      "'Korea Russia Iran ' => rec.autos\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Korea, Russia, Iran']\n",
    "\n",
    "# Filtering:\n",
    "docs_new = remove_punctuation(docs_new)\n",
    "docs_new =remove_stop_words(docs_new)\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, newsgroups_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpXg7GZW715L"
   },
   "source": [
    "#### 2.5.2. Hyperparameter tuning for random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjKYxSt38bxF"
   },
   "source": [
    "First we tune the maximum number of estmators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9jXVkiAf8caF",
    "outputId": "6339d074-8c3c-469a-86ac-6fca50c93f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.0s\n",
      "Cross-validation scores: [0.6243924  0.63543968 0.63499779 0.64604507 0.63881521]\n",
      "Cross-validation mean score: 0.6359380305088627\n",
      "CPU times: user 1min 27s, sys: 140 ms, total: 1min 27s\n",
      "Wall time: 1min 28s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.1s\n",
      "Cross-validation scores: [0.6447194  0.6447194  0.65620857 0.64913831 0.64190981]\n",
      "Cross-validation mean score: 0.6473390994091315\n",
      "CPU times: user 2min 48s, sys: 249 ms, total: 2min 49s\n",
      "Wall time: 2min 49s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  48.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  48.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  48.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  49.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  49.1s\n",
      "Cross-validation scores: [0.64692886 0.65311533 0.65620857 0.66239505 0.65605659]\n",
      "Cross-validation mean score: 0.6549408799458323\n",
      "CPU times: user 4min 11s, sys: 338 ms, total: 4min 11s\n",
      "Wall time: 4min 12s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "Cross-validation scores: [0.64560318 0.65355722 0.65709236 0.66062749 0.65959328]\n",
      "Cross-validation mean score: 0.655294705548412\n",
      "CPU times: user 5min 36s, sys: 411 ms, total: 5min 36s\n",
      "Wall time: 5min 37s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter n_estimators: 200\n",
      "Best accuracy: 0.655294705548412\n"
     ]
    }
   ],
   "source": [
    "ns = [50, 100, 150, 200]\n",
    "\n",
    "mu_max = 0\n",
    "n_best = ns[0]\n",
    "\n",
    "for n in ns:\n",
    "    %time scores, mu = cross_validation(model = RandomForestClassifier(n_estimators = n), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        n_best = n\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter n_estimators:\", n_best)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJLYgY0sEN4Q"
   },
   "source": [
    "Increasing the number of estimators affects the time required for training while accuracy does not increase much after 150, so it was decided to stop at 150."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z9FsbsWErGb"
   },
   "source": [
    "Next we tune `min_samples_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ra70iEbdEr0Y",
    "outputId": "63224f30-2867-4995-898f-565c10d6429b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  22.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  22.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.3s\n",
      "Cross-validation scores: [0.6548829  0.65841803 0.65753425 0.66106938 0.66489832]\n",
      "Cross-validation mean score: 0.6593605743102139\n",
      "CPU times: user 2min 2s, sys: 534 ms, total: 2min 3s\n",
      "Wall time: 2min 3s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.2s\n",
      "Cross-validation scores: [0.65178966 0.65753425 0.66283694 0.6650464  0.66489832]\n",
      "Cross-validation mean score: 0.6604211134175936\n",
      "CPU times: user 1min 39s, sys: 52.1 ms, total: 1min 39s\n",
      "Wall time: 1min 39s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  15.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  15.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.1s\n",
      "Cross-validation scores: [0.64737075 0.65134777 0.66460451 0.6650464  0.66091954]\n",
      "Cross-validation mean score: 0.6578577922704578\n",
      "CPU times: user 1min 27s, sys: 62.7 ms, total: 1min 27s\n",
      "Wall time: 1min 28s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.6s\n",
      "Cross-validation scores: [0.65311533 0.65709236 0.65355722 0.66460451 0.65959328]\n",
      "Cross-validation mean score: 0.6575925402810678\n",
      "CPU times: user 1min 21s, sys: 50.5 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  14.9s\n",
      "Cross-validation scores: [0.64560318 0.65444101 0.65753425 0.66018559 0.65959328]\n",
      "Cross-validation mean score: 0.6554714620663086\n",
      "CPU times: user 1min 18s, sys: 56.6 ms, total: 1min 18s\n",
      "Wall time: 1min 18s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  13.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.9s\n",
      "Cross-validation scores: [0.64383562 0.65532479 0.65797614 0.65841803 0.65428824]\n",
      "Cross-validation mean score: 0.6539685628140075\n",
      "CPU times: user 1min 13s, sys: 37.4 ms, total: 1min 13s\n",
      "Wall time: 1min 13s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.2s\n",
      "Cross-validation scores: [0.64781264 0.65267344 0.66327883 0.65841803 0.65870911]\n",
      "Cross-validation mean score: 0.6561784099961985\n",
      "CPU times: user 1min 10s, sys: 60.4 ms, total: 1min 10s\n",
      "Wall time: 1min 10s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.0s\n",
      "Cross-validation scores: [0.65090588 0.65223155 0.66637207 0.66372072 0.66268789]\n",
      "Cross-validation mean score: 0.6591836224380756\n",
      "CPU times: user 1min 7s, sys: 34.2 ms, total: 1min 7s\n",
      "Wall time: 1min 7s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.0s\n",
      "Cross-validation scores: [0.65002209 0.65532479 0.6597437  0.66195316 0.65473033]\n",
      "Cross-validation mean score: 0.65635481487646\n",
      "CPU times: user 1min 6s, sys: 40.9 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  11.6s\n",
      "Cross-validation scores: [0.65223155 0.65532479 0.65841803 0.66062749 0.65826702]\n",
      "Cross-validation mean score: 0.6569737752558847\n",
      "CPU times: user 1min 6s, sys: 36 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter min_samples_splits: 0.002\n",
      "Best accuracy: 0.6604211134175936\n"
     ]
    }
   ],
   "source": [
    "min_samples_splits = np.linspace(0.001, 0.01, 10, endpoint=True)\n",
    "\n",
    "mu_max = 0\n",
    "min_samples_split_max = min_samples_splits[0]\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "    %time scores, mu = cross_validation(model = RandomForestClassifier(n_estimators = 150, min_samples_split = min_samples_split), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        min_samples_split_max = min_samples_split\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter min_samples_splits:\", min_samples_split_max)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dKcb0V3cNNzA"
   },
   "source": [
    "Tuning `min_samples_leaf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jg9MdfHVNOIY",
    "outputId": "d96f55fc-a209-4c27-cb6d-8d4793d872e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.8s\n",
      "Cross-validation scores: [0.60848431 0.60362351 0.61157755 0.6296951  0.61892131]\n",
      "Cross-validation mean score: 0.6144603553962507\n",
      "CPU times: user 25.7 s, sys: 43.5 ms, total: 25.7 s\n",
      "Wall time: 25.8 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "Cross-validation scores: [0.57711003 0.55810871 0.58638975 0.58197084 0.5862069 ]\n",
      "Cross-validation mean score: 0.5779572432078262\n",
      "CPU times: user 19.1 s, sys: 40.7 ms, total: 19.2 s\n",
      "Wall time: 19.2 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "Cross-validation scores: [0.53336279 0.5329209  0.54087494 0.55501547 0.54509284]\n",
      "Cross-validation mean score: 0.5414533886732829\n",
      "CPU times: user 15.8 s, sys: 35.3 ms, total: 15.8 s\n",
      "Wall time: 15.9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "Cross-validation scores: [0.50287229 0.4975696  0.51347768 0.51038445 0.50839965]\n",
      "Cross-validation mean score: 0.5065407335082927\n",
      "CPU times: user 14.1 s, sys: 33 ms, total: 14.1 s\n",
      "Wall time: 14.1 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "Cross-validation scores: [0.4719399  0.47459125 0.48387097 0.4874061  0.47524315]\n",
      "Cross-validation mean score: 0.4786102733670046\n",
      "CPU times: user 12.7 s, sys: 28.3 ms, total: 12.7 s\n",
      "Wall time: 12.7 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "Cross-validation scores: [0.43923995 0.44586832 0.46752099 0.45735749 0.44606543]\n",
      "Cross-validation mean score: 0.45121043441704145\n",
      "CPU times: user 11.8 s, sys: 38.9 ms, total: 11.8 s\n",
      "Wall time: 11.9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "Cross-validation scores: [0.4365886  0.42421564 0.4467521  0.44189129 0.433687  ]\n",
      "Cross-validation mean score: 0.4366269277068186\n",
      "CPU times: user 11.4 s, sys: 31.4 ms, total: 11.4 s\n",
      "Wall time: 11.4 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "Cross-validation scores: [0.4007954  0.39726027 0.41979673 0.40963323 0.4040672 ]\n",
      "Cross-validation mean score: 0.4063105671407133\n",
      "CPU times: user 11 s, sys: 33.4 ms, total: 11 s\n",
      "Wall time: 11 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "Cross-validation scores: [0.38444543 0.36853734 0.39946973 0.37914273 0.38549956]\n",
      "Cross-validation mean score: 0.38341895709747353\n",
      "CPU times: user 10.6 s, sys: 38.1 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "Cross-validation scores: [0.36102519 0.34114008 0.36323464 0.36676977 0.35543767]\n",
      "Cross-validation mean score: 0.3575214704079348\n",
      "CPU times: user 10.5 s, sys: 34 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter min_samples_leaf: 0.001\n",
      "Best accuracy: 0.6144603553962507\n"
     ]
    }
   ],
   "source": [
    "min_samples_leafs = np.linspace(0.001, 0.01, 10, endpoint=True)\n",
    "\n",
    "mu_max = 0\n",
    "min_samples_leaf_max = min_samples_leafs[0]\n",
    "\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    %time scores, mu = cross_validation(model = RandomForestClassifier(n_estimators = 150, min_samples_split = 0.002, min_samples_leaf = min_samples_leaf), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        min_samples_leaf_max = min_samples_leaf\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter min_samples_leaf:\", min_samples_leaf_max)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrf8QbH_V7B-"
   },
   "source": [
    "#### 2.5.3. Building a pipeline for random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqvdbXlNXwXg"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cFAifP2V4kf"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators = 150, min_samples_split = 0.002, min_samples_leaf = 0.001)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6neN13qX3ed"
   },
   "source": [
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "WDD-C_LzX17Q",
    "outputId": "e190645e-ab84-4a9e-a1b0-0ec6c641a6c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=0.001,\n",
       "                                        min_samples_split=0.002,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=150, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(filtered_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iG5QZ4pUZYpX"
   },
   "source": [
    "#### 2.5.4. Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "07_HpeQVZX0N",
    "outputId": "445e5d80-4d8e-4982-b995-7328ed1eb09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.5872278279341476\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(filtered_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "UtUj339VRyAK",
    "outputId": "6cf59eb6-4657-4b47-97ac-cd27cede56c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.53      0.27      0.35       319\n",
      "           comp.graphics       0.54      0.56      0.55       389\n",
      " comp.os.ms-windows.misc       0.55      0.59      0.57       394\n",
      "comp.sys.ibm.pc.hardware       0.56      0.56      0.56       392\n",
      "   comp.sys.mac.hardware       0.70      0.57      0.63       385\n",
      "          comp.windows.x       0.64      0.64      0.64       395\n",
      "            misc.forsale       0.66      0.74      0.70       390\n",
      "               rec.autos       0.62      0.63      0.63       396\n",
      "         rec.motorcycles       0.32      0.73      0.44       398\n",
      "      rec.sport.baseball       0.68      0.68      0.68       397\n",
      "        rec.sport.hockey       0.74      0.83      0.78       399\n",
      "               sci.crypt       0.74      0.64      0.69       396\n",
      "         sci.electronics       0.48      0.40      0.43       393\n",
      "                 sci.med       0.72      0.60      0.65       396\n",
      "               sci.space       0.75      0.62      0.68       394\n",
      "  soc.religion.christian       0.51      0.79      0.62       398\n",
      "      talk.politics.guns       0.49      0.60      0.54       364\n",
      "   talk.politics.mideast       0.80      0.69      0.74       376\n",
      "      talk.politics.misc       0.62      0.26      0.37       310\n",
      "      talk.religion.misc       0.47      0.03      0.06       251\n",
      "\n",
      "                accuracy                           0.59      7532\n",
      "               macro avg       0.61      0.57      0.57      7532\n",
      "            weighted avg       0.61      0.59      0.58      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "                                    target_names = newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rW6NtY-mlnbv"
   },
   "source": [
    "### 2.6. Multinominal Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wl0FBcvrnikQ"
   },
   "source": [
    "We see that the results from the previous sections are not very encouraging except for the SVM classifier which approaches a 70% accuracy. It was decided to apply Multinominal Naive Bayes as it is easy to implement and fast to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChONZzU6ZyyS"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eE4nNtNTQBic"
   },
   "source": [
    "#### 2.6.1. Training the multinominal naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_L2FmrqVl_S2"
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "-ewvvYnQmCxp",
    "outputId": "928fd4a5-7473-41ec-daf3-5f59ce2fe093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God love ' => soc.religion.christian\n",
      "'OpenGL GPU fast ' => comp.graphics\n",
      "'Korea Russia Iran ' => talk.politics.mideast\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Korea, Russia, Iran']\n",
    "\n",
    "# Filtering:\n",
    "docs_new = remove_punctuation(docs_new)\n",
    "docs_new = remove_stop_words(docs_new)\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, newsgroups_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dO183HHxQKa3"
   },
   "source": [
    "#### 2.6.2. Hyperparameter tuning for multinominal naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zpI4fnXAQQeX"
   },
   "source": [
    "Tuning $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OhHrVZf-Qawn",
    "outputId": "5014b5ad-fb27-495a-9a9b-50548a2b62c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Cross-validation scores: [0.72425983 0.72470172 0.73884224 0.74900574 0.74535809]\n",
      "Cross-validation mean score: 0.7364335270075285\n",
      "CPU times: user 9.13 s, sys: 388 ms, total: 9.52 s\n",
      "Wall time: 9.68 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Cross-validation scores: [0.73795846 0.73884224 0.74900574 0.7565179  0.75596817]\n",
      "Cross-validation mean score: 0.7476585035943226\n",
      "CPU times: user 8.57 s, sys: 333 ms, total: 8.9 s\n",
      "Wall time: 9 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   2.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Cross-validation scores: [0.74149359 0.74768007 0.75298277 0.76049492 0.76215738]\n",
      "Cross-validation mean score: 0.7529617461230973\n",
      "CPU times: user 9.28 s, sys: 374 ms, total: 9.65 s\n",
      "Wall time: 9.96 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Cross-validation scores: [0.74768007 0.74502872 0.75563411 0.76049492 0.75862069]\n",
      "Cross-validation mean score: 0.7534917031100005\n",
      "CPU times: user 9.47 s, sys: 404 ms, total: 9.88 s\n",
      "Wall time: 10.2 s\n",
      "-----------------------------------------------------------------\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "Cross-validation scores: [0.74281927 0.73795846 0.74458683 0.74988953 0.7515473 ]\n",
      "Cross-validation mean score: 0.7453602781531836\n",
      "CPU times: user 9.23 s, sys: 394 ms, total: 9.63 s\n",
      "Wall time: 10.4 s\n",
      "-----------------------------------------------------------------\n",
      "Best hyperparameter alpha: 0.05\n",
      "Best accuracy: 0.7534917031100005\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "mu_max = 0\n",
    "alpha_best = alphas[0]\n",
    "\n",
    "for alpha in alphas:\n",
    "    %time scores, mu = cross_validation(model = MultinomialNB(alpha = alpha), X = filtered_train, y = newsgroups_train.target, folds = 5)\n",
    "\n",
    "    if (mu > mu_max):\n",
    "        mu_max = mu\n",
    "        alpha_best = alpha\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Best hyperparameter alpha:\", alpha_best)\n",
    "print(\"Best accuracy:\", mu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03f4xmrARdNH"
   },
   "source": [
    " #### 2.6.3. Building a pipeline for multinominal naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QA5NRKdvRj4k"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjgMjVvZmsMw"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha = 0.05)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuzbaG3ARkjU"
   },
   "source": [
    "\n",
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "Tzc4eocym20j",
    "outputId": "affa560e-4535-44d4-cda9-748af0c33af9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.05, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(filtered_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dZSUPOkRoEr"
   },
   "source": [
    "#### 2.6.4. Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y-W8SCLznGoR",
    "outputId": "783b9c18-be60-439b-a1d7-88d0860f2279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.694105151354222\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(filtered_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "03ZhjKjuSIAD",
    "outputId": "613eb103-f475-492a-d3dc-39783a13ca86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.63      0.38      0.48       319\n",
      "           comp.graphics       0.65      0.67      0.66       389\n",
      " comp.os.ms-windows.misc       0.69      0.56      0.62       394\n",
      "comp.sys.ibm.pc.hardware       0.61      0.72      0.66       392\n",
      "   comp.sys.mac.hardware       0.74      0.68      0.71       385\n",
      "          comp.windows.x       0.78      0.73      0.76       395\n",
      "            misc.forsale       0.83      0.74      0.78       390\n",
      "               rec.autos       0.80      0.72      0.76       396\n",
      "         rec.motorcycles       0.77      0.76      0.76       398\n",
      "      rec.sport.baseball       0.91      0.83      0.87       397\n",
      "        rec.sport.hockey       0.59      0.93      0.72       399\n",
      "               sci.crypt       0.67      0.76      0.71       396\n",
      "         sci.electronics       0.71      0.57      0.63       393\n",
      "                 sci.med       0.85      0.77      0.81       396\n",
      "               sci.space       0.77      0.79      0.78       394\n",
      "  soc.religion.christian       0.49      0.91      0.64       398\n",
      "      talk.politics.guns       0.56      0.74      0.64       364\n",
      "   talk.politics.mideast       0.80      0.80      0.80       376\n",
      "      talk.politics.misc       0.67      0.42      0.52       310\n",
      "      talk.religion.misc       0.49      0.08      0.13       251\n",
      "\n",
      "                accuracy                           0.69      7532\n",
      "               macro avg       0.70      0.68      0.67      7532\n",
      "            weighted avg       0.71      0.69      0.68      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "                                    target_names = newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7q6a3Ize-zE"
   },
   "source": [
    "## 3. Using normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0jRNJRdev9X"
   },
   "source": [
    "The accuracy of multinominal Naive Bayes is slightly better than of SVM, but there is still some room for improvement. In this section, multinominal Naive Bayes and SVM are applied to normalized data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBdca8vegSid"
   },
   "source": [
    "First the normalized dataset is loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osDgKL_5gYF7"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mt92ktPfgn6V"
   },
   "outputs": [],
   "source": [
    "newsgroups_train_normalized = fetch_20newsgroups_vectorized(subset = 'train',\n",
    "                                                            remove = ('headers', 'footers', 'quotes'),\n",
    "                                                            normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INOZHhX_fwH5"
   },
   "source": [
    "### 3.1. Applying SVM to normalized data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnrcmbdYgPBJ"
   },
   "source": [
    "#### 3.1.1. Training the SVM classifier on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2WmOgwAJTQj"
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(C = 0.5).fit(newsgroups_train_normalized.data, newsgroups_train_normalized.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMu-wYQDgPxM"
   },
   "source": [
    "#### 3.1.2. Building a pipeline for SVM with normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lANusiEgQNU"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_oCC5l1QvCP"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC(C = 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_nuSk_IQQ8Sc"
   },
   "source": [
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Fs0CWTlsRXU7",
    "outputId": "58b25c9d-c883-4368-fd82-8f54fc391c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=0.5, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 279,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(newsgroups_train_normalized.data, newsgroups_train_normalized.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THpbbFKwgQle"
   },
   "source": [
    "#### 3.1.3. Evaluation of the performance of SVM on the normalized test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-rHcoRFgQ8O"
   },
   "source": [
    "Loading the test dataset and predicting its target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EoNn9zcpSFdS",
    "outputId": "710eb044-6a3a-4a4b-e9d6-6ae29cbb4663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6980881571959638\n"
     ]
    }
   ],
   "source": [
    "newsgroups_test_normalized = fetch_20newsgroups_vectorized(subset = 'test',\n",
    "                                                remove = ('headers', 'footers', 'quotes'),\n",
    "                                                normalize = True)\n",
    "docs_test = newsgroups_test_normalized.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test_normalized.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "KMasR7-Vt1XP",
    "outputId": "730787dc-b535-4195-bd81-9ed4928d147a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.53      0.49      0.51       319\n",
      "           comp.graphics       0.67      0.72      0.69       389\n",
      " comp.os.ms-windows.misc       0.63      0.62      0.63       394\n",
      "comp.sys.ibm.pc.hardware       0.65      0.66      0.66       392\n",
      "   comp.sys.mac.hardware       0.74      0.70      0.72       385\n",
      "          comp.windows.x       0.82      0.71      0.76       395\n",
      "            misc.forsale       0.77      0.80      0.78       390\n",
      "               rec.autos       0.76      0.71      0.74       396\n",
      "         rec.motorcycles       0.79      0.77      0.78       398\n",
      "      rec.sport.baseball       0.55      0.83      0.66       397\n",
      "        rec.sport.hockey       0.87      0.87      0.87       399\n",
      "               sci.crypt       0.85      0.71      0.78       396\n",
      "         sci.electronics       0.62      0.59      0.61       393\n",
      "                 sci.med       0.79      0.77      0.78       396\n",
      "               sci.space       0.75      0.75      0.75       394\n",
      "  soc.religion.christian       0.64      0.81      0.72       398\n",
      "      talk.politics.guns       0.60      0.68      0.64       364\n",
      "   talk.politics.mideast       0.81      0.77      0.79       376\n",
      "      talk.politics.misc       0.57      0.47      0.52       310\n",
      "      talk.religion.misc       0.48      0.29      0.36       251\n",
      "\n",
      "                accuracy                           0.70      7532\n",
      "               macro avg       0.69      0.69      0.69      7532\n",
      "            weighted avg       0.70      0.70      0.70      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test_normalized.target, predicted,\n",
    "                                    target_names = newsgroups_test_normalized.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1aRF8yvSnSR"
   },
   "source": [
    "### 3.2. Applying multinominal Naive Bayes to normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IG08XgXeSuJn"
   },
   "source": [
    "#### 3.2.1. Training the multinominal Naive Bayes classifier on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5K1sZKZ_TDZD"
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha = 0.01).fit(newsgroups_train_normalized.data, newsgroups_train_normalized.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAO-pRLWSzpw"
   },
   "source": [
    "#### 3.2.2. Building a pipeline for multinominal Naive Bayes with normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLE2yNXXTu_M"
   },
   "source": [
    "A pipeline is built to make the model to be easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1ek4lYnTr7T"
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha = 0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ci0C-IW6T1ad"
   },
   "source": [
    "The model can be trained much simplier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-_ItMUi9T4ft",
    "outputId": "b9e100f4-a75c-4a93-e713-b3b27c6d07cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 284,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(newsgroups_train_normalized.data, newsgroups_train_normalized.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEgXLPU7UN_g"
   },
   "source": [
    "#### 3.2.3. Evaluation of the performance of multinominal Naive Bayes on the normalized test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dNQSJLQNUZf4",
    "outputId": "d76b9caa-b1a9-4280-b1c1-5e74c84b8ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7002124269782263\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(docs_test)\n",
    "print(\"Average accuracy:\", np.mean(predicted == newsgroups_test_normalized.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "qQI9i4z6t4RB",
    "outputId": "645f84de-c634-456b-aa43-db783eb48d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.57      0.44      0.50       319\n",
      "           comp.graphics       0.65      0.71      0.68       389\n",
      " comp.os.ms-windows.misc       0.72      0.52      0.60       394\n",
      "comp.sys.ibm.pc.hardware       0.59      0.71      0.65       392\n",
      "   comp.sys.mac.hardware       0.72      0.70      0.71       385\n",
      "          comp.windows.x       0.81      0.74      0.78       395\n",
      "            misc.forsale       0.83      0.72      0.77       390\n",
      "               rec.autos       0.75      0.73      0.74       396\n",
      "         rec.motorcycles       0.76      0.73      0.75       398\n",
      "      rec.sport.baseball       0.93      0.81      0.87       397\n",
      "        rec.sport.hockey       0.60      0.93      0.73       399\n",
      "               sci.crypt       0.72      0.75      0.74       396\n",
      "         sci.electronics       0.72      0.58      0.64       393\n",
      "                 sci.med       0.82      0.78      0.80       396\n",
      "               sci.space       0.76      0.79      0.77       394\n",
      "  soc.religion.christian       0.56      0.89      0.68       398\n",
      "      talk.politics.guns       0.58      0.73      0.65       364\n",
      "   talk.politics.mideast       0.82      0.81      0.81       376\n",
      "      talk.politics.misc       0.62      0.45      0.52       310\n",
      "      talk.religion.misc       0.51      0.19      0.27       251\n",
      "\n",
      "                accuracy                           0.70      7532\n",
      "               macro avg       0.70      0.69      0.68      7532\n",
      "            weighted avg       0.71      0.70      0.69      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test_normalized.target, predicted,\n",
    "                                    target_names = newsgroups_test_normalized.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtZp3hy0UdYb"
   },
   "source": [
    "### 3.3. Normalization results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8FHj0fmQUhaM"
   },
   "source": [
    "Note that normalization affects the accuracy insignificantly in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6D2Me-H1tXoF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COMP 551 - Mini-Project 2 - 20 newsgroups.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
